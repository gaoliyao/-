{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reflection Logistic Regression Experiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaoliyao/-/blob/master/Reflection_Logistic_Regression_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qPQGOz2dPKFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "d07023ed-2993-4c41-dd67-6dbdddd4d3f4"
      },
      "cell_type": "code",
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 22kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59450000 @  0x7fb9c55e12a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hCollecting scikit-learn==0.20.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b2/05be9b6da9ae4a4c54f537be22e95833f722742a02b1e355fdc09363877c/scikit_learn-0.20.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 4.1MB/s \n",
            "\u001b[?25hCollecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/9e/6a1f51fe538005d4fc2b28c270ffa0a2186ee4de345428811823bb4ba6eb/skorch-0.4.0-py3-none-any.whl (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.14.6)\n",
            "Collecting tabulate (from skorch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 17.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Building wheels for collected packages: tabulate\n",
            "  Running setup.py bdist_wheel for tabulate ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
            "Successfully built tabulate\n",
            "Installing collected packages: torch, scikit-learn, tabulate, skorch\n",
            "  Found existing installation: scikit-learn 0.19.2\n",
            "    Uninstalling scikit-learn-0.19.2:\n",
            "      Successfully uninstalled scikit-learn-0.19.2\n",
            "Successfully installed scikit-learn-0.20.0 skorch-0.4.0 tabulate-0.8.2 torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OexME6nIQVmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57ce775a-03c9-427e-cb8a-d75ca603b565"
      },
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZ7SQU1tRvS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twHxAyXETU-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Reflection:\n",
        "    def __init__(self):\n",
        "        self.performance = 0\n",
        "        self.classifierDict = {} \n",
        "        self.trainData = []  # FloatTensor [{}, {}]\n",
        "        self.trainLabel = [] # LongTensor [{}, {}]\n",
        "        self.taskClassifier = None\n",
        "        self.errorTaskClassifier = [] #[{}, {}]\n",
        "        self.correctAndWrongSet = {} #[{}, {}]\n",
        "\n",
        "    def train(self, x, y):\n",
        "          print(\"Start training NN\")\n",
        "\n",
        "          diff = self.trainSingleNeuralNetwork(len(self.classifierDict), x, y)\n",
        "          self.reflect(0, x, y, diff)\n",
        "          print(\"Ready to train taskClassifier\")\n",
        "          self.correctAndWrongSet[0] = self.trainData[0]\n",
        "          taskClassifier = TaskClassifierLayer(self.correctAndWrongSet)\n",
        "          self.taskClassifier = taskClassifier\n",
        "              \n",
        "    # Input: FloatTensor, LongTensor, list\n",
        "    # Return: FloatTensor, LongTensor\n",
        "    def getError(self, x, y, diff):\n",
        "          x = x.data.numpy()\n",
        "          y = y.data.numpy()\n",
        "          max = -1000\n",
        "          for i in diff:\n",
        "              if i > max:\n",
        "                  max = i\n",
        "          #print(max)\n",
        "\n",
        "          newX = []\n",
        "          newY = []\n",
        "          #print(diff)\n",
        "          for j in range(0, len(diff)):\n",
        "              if abs(diff[j]) > 0:\n",
        "                  #print(diff[j])\n",
        "                  k = x[j]\n",
        "                  newX.append(k.tolist())\n",
        "                  newY.append(y[j].tolist())\n",
        "          newX = torch.FloatTensor(newX)\n",
        "          newY = torch.LongTensor(newY)\n",
        "          return newX, newY\n",
        "    def reflect(self, id, x, y, diff):\n",
        "          newX, newY = self.getError(x, y, diff)\n",
        "          errorTaskClassifier = KMeans(n_clusters=8, init='k-means++', random_state=0)\n",
        "          \n",
        "          newY = newY.numpy()\n",
        "          newX = newX.numpy()\n",
        "          print(newY)\n",
        "          print(\"Ready to train taskClassifier\")\n",
        "          errorTaskClassifier.fit(newY)\n",
        "          self.errorTaskClassifier.append(errorTaskClassifier)\n",
        "          X0 = []\n",
        "          y0 = []\n",
        "          X1 = []\n",
        "          y1 = []\n",
        "          X2 = []\n",
        "          y2 = []\n",
        "          X3 = []\n",
        "          y3 = []\n",
        "          X4 = []\n",
        "          y4 = []\n",
        "          X5 = []\n",
        "          y5 = []\n",
        "          X6 = []\n",
        "          y6 = []\n",
        "          X7 = []\n",
        "          y7 = []\n",
        "          print(\"Ready to train operatorNetwork\")\n",
        "          for i in range(0, len(newY)):\n",
        "              data = newX[i]\n",
        "              target = newY[i]\n",
        "              clusterId = self.errorTaskClassifier[id].predict([target])\n",
        "              if i % 100 == 0:\n",
        "                  print(\"=======\")\n",
        "                  print(newY[i])\n",
        "                  print(clusterId)\n",
        "                  print(\"=======\")\n",
        "              data = data.tolist()\n",
        "              target = target.tolist()\n",
        "              if clusterId == 0:\n",
        "                  X0.append(data)\n",
        "                  y0.append(target)\n",
        "              elif clusterId == 1:\n",
        "                  X1.append(data)\n",
        "                  y1.append(target)\n",
        "              elif clusterId == 2:\n",
        "                  X2.append(data)\n",
        "                  y2.append(target)\n",
        "              elif clusterId == 3:\n",
        "                  X3.append(data)\n",
        "                  y3.append(target)\n",
        "              elif clusterId == 4:\n",
        "                  X4.append(data)\n",
        "                  y4.append(target)\n",
        "              elif clusterId == 5:\n",
        "                  X5.append(data)\n",
        "                  y5.append(target)\n",
        "              elif clusterId == 6:\n",
        "                  X6.append(data)\n",
        "                  y6.append(target)\n",
        "              elif clusterId == 7:\n",
        "                  X7.append(data)\n",
        "                  y7.append(target)\n",
        "\n",
        "          \n",
        "          self.correctAndWrongSet[1] = Variable(torch.FloatTensor(X0))\n",
        "          self.correctAndWrongSet[2] = Variable(torch.FloatTensor(X1))\n",
        "          self.correctAndWrongSet[3] = Variable(torch.FloatTensor(X2))\n",
        "          self.correctAndWrongSet[4] = Variable(torch.FloatTensor(X3))\n",
        "          self.correctAndWrongSet[5] = Variable(torch.FloatTensor(X4))\n",
        "          self.correctAndWrongSet[6] = Variable(torch.FloatTensor(X5))\n",
        "          self.correctAndWrongSet[7] = Variable(torch.FloatTensor(X6))\n",
        "          self.correctAndWrongSet[8] = Variable(torch.FloatTensor(X7))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X0)), Variable(torch.LongTensor(y0)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X1)), Variable(torch.LongTensor(y1)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X2)), Variable(torch.LongTensor(y2)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X3)), Variable(torch.LongTensor(y3)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X4)), Variable(torch.LongTensor(y4)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X5)), Variable(torch.LongTensor(y5)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X6)), Variable(torch.LongTensor(y6)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X7)), Variable(torch.LongTensor(y7)))\n",
        "\n",
        "    def reflctWithoutKmeans(self, id, x, y, diff):\n",
        "        newX, newY = self.getError(x, y, diff)\n",
        "          \n",
        "        newY = newY.numpy()\n",
        "        newX = newX.numpy()\n",
        "        print(\"Ready to train taskClassifier\")\n",
        "        X0 = newX\n",
        "        y0 = newY\n",
        "          \n",
        "        self.correctAndWrongSet[id][1] = Variable(torch.FloatTensor(X0))\n",
        "        self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X0)), Variable(torch.LongTensor(y0)))\n",
        "          \n",
        "\n",
        "        \n",
        "    def convertNumpyToFloatList(self, x):\n",
        "        x = x.tolist()\n",
        "        x = torch.FloatTensor(x)\n",
        "        return x\n",
        "    # Input int, FloatTensor, LongTensor\n",
        "    # Output list\n",
        "    def trainSingleNeuralNetwork(self, num, X, y):\n",
        "        print(\"Train Single NN\")\n",
        "        print(\"number\", num)\n",
        "        print(\"x\", len(X))\n",
        "        #s = x.data.numpy().shape\n",
        "        print(type(X))\n",
        "        print(type(y))\n",
        "        clf = None\n",
        "        diff = []\n",
        "        print(__doc__)\n",
        "\n",
        "        # Author: Arthur Mensch <arthur.mensch@m4x.org>\n",
        "        # License: BSD 3 clause\n",
        "\n",
        "        # Turn down for faster convergence\n",
        "        t0 = time.time()\n",
        "        train_samples = 5000\n",
        "\n",
        "        # Load data from https://www.openml.org/d/554\n",
        "        #X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "\n",
        "        random_state = check_random_state(0)\n",
        "        permutation = random_state.permutation(X.shape[0])\n",
        "        X = X[permutation]\n",
        "        y = y[permutation]\n",
        "        X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        #X_train, X_test, y_train, y_test = train_test_split(\n",
        "        #    X, y, train_size=train_samples, test_size=10000)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "        #X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Turn up tolerance for faster convergence\n",
        "        clf = LogisticRegression(C=50. / train_samples,\n",
        "                                 multi_class='multinomial',\n",
        "                                 penalty='l1', solver='saga', tol=0.1)\n",
        "        clf.fit(X, y)\n",
        "        sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "        score = clf.score(X, y)\n",
        "        #print('Best C % .4f' % clf.C_)\n",
        "        print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "        print(\"Test score with L1 penalty: %.4f\" % score)\n",
        "\n",
        "        coef = clf.coef_.copy()\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        scale = np.abs(coef).max()\n",
        "        for i in range(10):\n",
        "            l1_plot = plt.subplot(2, 5, i + 1)\n",
        "            l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
        "                           cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
        "            l1_plot.set_xticks(())\n",
        "            l1_plot.set_yticks(())\n",
        "            l1_plot.set_xlabel('Class %i' % i)\n",
        "        plt.suptitle('Classification vector for...')\n",
        "\n",
        "        run_time = time.time() - t0\n",
        "        print('Example run in %.3f s' % run_time)\n",
        "        plt.show()\n",
        "        for i in range(0, len(x)):\n",
        "            prediction = clf.predict(x[i])\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "            diff.append(prediction.numpy()[0] - y.numpy()[i][0])\n",
        "\n",
        "        print('Finished Training')\n",
        "            \n",
        "        \n",
        "        self.classifierDict[num] = clf\n",
        "        self.trainData.append(x)\n",
        "        self.trainLabel.append(y)\n",
        "        \n",
        "        #print(len(x))\n",
        "        \n",
        "        #print(diff)\n",
        "        return diff\n",
        "\n",
        "    def test(self):\n",
        "        return 0.5\n",
        "\n",
        "    def getDifference(self, x, diff):\n",
        "        pass\n",
        "\n",
        "    def predict(self, data):\n",
        "        prediction = []\n",
        "        #for data in X:\n",
        "        data = data.data.numpy().tolist()\n",
        "        data = Variable(torch.FloatTensor(data))\n",
        "        \n",
        "        #print(len(self.taskClassifier))\n",
        "        #taskId = self.sensoryCortex.predictSensoryID(data.data.numpy().tolist())\n",
        "        #print(taskId)\n",
        "        predictClusterId = self.taskClassifier.predictCluster(data)\n",
        "        net= self.classifierDict[predictClusterId[0]]\n",
        "        for nId in self.classifierDict.keys():\n",
        "            n = self.classifierDict[nId]\n",
        "            output = n(data)\n",
        "            shapeData = data.data.numpy().shape\n",
        "            if shapeData[3] == 28:                \n",
        "                _, prediction = torch.max(output.data, 1)\n",
        "            else:\n",
        "                _, prediction = torch.max(output.data, 1)\n",
        "        predictOutput = net(data)\n",
        "        \n",
        "        return predictOutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_UdKr0GTWJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.autograd import Variable\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from torch.autograd import Variable\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class TaskClassifierLayer:\n",
        "    def __init__(self, correctAndWrongCluster):\n",
        "        self.correctAndWrongVariables = correctAndWrongCluster\n",
        "        self.correctAndWrong = {}\n",
        "#         self.clf3 = LogisticRegression(C=50. / 70000, multi_class='multinomial', penalty='l1', solver='saga', tol=0.1)\n",
        "        self.clf = tree.DecisionTreeClassifier()\n",
        "#        self.clf2 = GaussianNB()\n",
        "#         self.clf4 = KNeighborsClassifier(3)\n",
        "#         self.clf5 = MLPClassifier(alpha=1)\n",
        "#         self.clf6 =  AdaBoostClassifier()\n",
        "#         self.clf7 = SVC(gamma=2, C=1)\n",
        "#         self.clf8 = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "        self.getCorrectAndWrongCluster()\n",
        "        self.trainClassifier()\n",
        "    def getCorrectAndWrongCluster(self):\n",
        "        #print(self.correctAndWrong)\n",
        "        # list output in this for loop\n",
        "        for i in self.correctAndWrongVariables.keys():\n",
        "            j = self.correctAndWrongVariables[i]\n",
        "            j = j.data.numpy()\n",
        "            for num in j:\n",
        "                if i not in self.correctAndWrong.keys():\n",
        "                    self.correctAndWrong[i] = [num[0]]\n",
        "                else:\n",
        "                    self.correctAndWrong[i].append(num[0])\n",
        "        for i in self.correctAndWrong.keys():\n",
        "            if i != 0:\n",
        "                for j in self.correctAndWrong[i]:\n",
        "                    #newCluster = self.clusters[0]\n",
        "                    for k in range(0, len(self.correctAndWrong[0])):\n",
        "                        if np.array_equal(np.array(self.correctAndWrong[0][k]), np.array(j)):\n",
        "                            self.correctAndWrong[0].pop(k)\n",
        "                            break\n",
        "        print(\"data ready\")\n",
        "        \n",
        "                            \n",
        "        #print(self.clusters[0])\n",
        "        \n",
        "    def trainClassifier(self):\n",
        "        X = []\n",
        "        y = []\n",
        "        for i in self.correctAndWrong.keys():\n",
        "            print(i)\n",
        "            cluster = self.correctAndWrong[i]\n",
        "            #print(cluster)\n",
        "            for j in cluster:\n",
        "                X.append([j])\n",
        "                y.append(i)\n",
        "        #print(X)\n",
        "        #print(y)\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        #print(X.shape)\n",
        "        #print(y.shape)\n",
        "        num, color, pic, pixX, pixY = X.shape\n",
        "        X = X.reshape(num, pixX*pixY*color*pic)\n",
        "        num = y.shape\n",
        "        y = y.reshape(num)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "#         self.clf = self.clf.fit(X_train, y_train)\n",
        "#         prediction = self.clf.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork DT\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction))\n",
        "        \n",
        "#         self.clf2 = self.clf2.fit(X_train, y_train)\n",
        "#         prediction2 = self.clf2.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork GaussianNB\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction2))\n",
        "        \n",
        "#         self.clf3 = self.clf3.fit(X_train, y_train)\n",
        "#         prediction3 = self.clf3.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork LogReg\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction3))\n",
        "        \n",
        "        self.clf = self.clf.fit(X_train, y_train)\n",
        "#         prediction2 = self.clf.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork KNeighborsClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction2))\n",
        "        \n",
        "#         self.clf5 = self.clf5.fit(X_train, y_train)\n",
        "#         prediction = self.clf5.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork MLPClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction))\n",
        "        \n",
        "#         self.clf6 = self.clf6.fit(X_train, y_train)\n",
        "#         prediction6 = self.clf6.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork AdaBoostClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction6))\n",
        "        \n",
        "#         self.clf7 = self.clf7.fit(X_train, y_train)       \n",
        "#         prediction7 = self.clf7.predict(X_test)    \n",
        "#         print(\"performanceNeuralNetwork SVC\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction7))\n",
        "#sffs\n",
        "        \n",
        "\n",
        "    def getClusters(self):\n",
        "        # list output in this for loop\n",
        "        for i in self.clustersVariables.keys():\n",
        "            j = self.clustersVariables[i]\n",
        "            j = j.data.numpy()\n",
        "            for num in j:\n",
        "                if i not in self.clusters.keys():\n",
        "                    self.clusters[i] = [num[0]]\n",
        "                else:\n",
        "                    self.clusters[i].append(num[0])\n",
        "        for i in self.clusters.keys():\n",
        "            if i != 0:\n",
        "                for j in self.clusters[i]:\n",
        "                    #newCluster = self.clusters[0]\n",
        "                    for k in range(0, len(self.clusters[0])):\n",
        "                        if np.array_equal(np.array(self.clusters[0][k]), np.array(j)):\n",
        "                            self.clusters[0].pop(k)\n",
        "                            break\n",
        "                            \n",
        "        #print(self.clusters[0])\n",
        "    # Variable\n",
        "    def predictCluster(self, x):\n",
        "        #print(self.clusterRanges)\n",
        "        num, color, pixX, pixY = x.shape\n",
        "        x = x.data.numpy()\n",
        "        x = x.reshape(num, pixX*pixY*color)\n",
        "        clusterId = self.clf.predict(x)\n",
        "        return clusterId\n",
        "    def dist(self, a, b):\n",
        "        return abs(a-b)\n",
        "    def my_custom_loss_func(self, ground_truth, predictions):\n",
        "        diff = np.abs(ground_truth - predictions)\n",
        "        num = 0.0\n",
        "        count = 0.0\n",
        "        for i in diff:\n",
        "            count += 1\n",
        "            if i == 0:\n",
        "                num += 1\n",
        "        return float(num)/float(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ep7jozd5VKDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "068b43d4-6f09-4b24-eee3-a91838ebbe9a"
      },
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "print(len(X))\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fyOARcKU8Fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1816
        },
        "outputId": "8d5bf8ca-4737-4a98-c4f1-4af091e2b05c"
      },
      "cell_type": "code",
      "source": [
        "c = Reflection()\n",
        "print(len(X_train))\n",
        "c.train(X_train, y_train)\n",
        "#c.train(EMNIST_trainloader, EMNIST_testloader)\n",
        "\n",
        "\n",
        "# for i in c.taskClassifier.clusters.keys():\n",
        "X_test = scaler.transform(X_test)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Test score with L1 penalty: %.4f\" % score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "Start training NN\n",
            "Train Single NN\n",
            "number 0\n",
            "x 5000\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-99824ec9d907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReflection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#c.train(EMNIST_trainloader, EMNIST_testloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-1003aa952f75>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training NN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSingleNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifierDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ready to train taskClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-1003aa952f75>\u001b[0m in \u001b[0;36mtrainSingleNeuralNetwork\u001b[0;34m(self, num, X, y)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                  \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                  penalty='l1', solver='saga', tol=0.1)\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0msparsity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1357\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1359\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    329\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         warnings.warn(\"The max_iter was reached which means \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aP8pb3-8O9wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1796
        },
        "outputId": "d5dad700-ce64-492a-b31e-a57d6af74f4e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "# Author: Arthur Mensch <arthur.mensch@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "# Turn down for faster convergence\n",
        "t0 = time.time()\n",
        "train_samples = 5000\n",
        "\n",
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Turn up tolerance for faster convergence\n",
        "clf = LogisticRegression(C=50. / train_samples,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l1', solver='saga', tol=0.1)\n",
        "clf.fit(X_train, y_train)\n",
        "sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "score = clf.score(X_test, y_test)\n",
        "# print('Best C % .4f' % clf.C_)\n",
        "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "print(\"Test score with L1 penalty: %.4f\" % score)\n",
        "\n",
        "coef = clf.coef_.copy()\n",
        "plt.figure(figsize=(10, 5))\n",
        "scale = np.abs(coef).max()\n",
        "for i in range(10):\n",
        "    l1_plot = plt.subplot(2, 5, i + 1)\n",
        "    l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
        "                   cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
        "    l1_plot.set_xticks(())\n",
        "    l1_plot.set_yticks(())\n",
        "    l1_plot.set_xlabel('Class %i' % i)\n",
        "plt.suptitle('Classification vector for...')\n",
        "\n",
        "run_time = time.time() - t0\n",
        "print('Example run in %.3f s' % run_time)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-677bd1048601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load data from https://www.openml.org/d/554\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;31m# obtain the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     arff = _download_data_arff(data_description['file_id'], return_sparse,\n\u001b[0;32m--> 544\u001b[0;31m                                data_home)\n\u001b[0m\u001b[1;32m    545\u001b[0m     \u001b[0marff_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     nominal_attributes = {k: v for k, v in arff['attributes']\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/openml.py\u001b[0m in \u001b[0;36m_download_data_arff\u001b[0;34m(file_id, sparse, data_home, encode_nominal)\u001b[0m\n\u001b[1;32m    323\u001b[0m                                return_type=return_type, )\n\u001b[1;32m    324\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         arff_file = _arff.loads(response.read().decode('utf-8'),\n\u001b[0m\u001b[1;32m    326\u001b[0m                                 \u001b[0mencode_nominal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_nominal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                                 return_type=return_type)\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Read a chunk of data from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}